---
!ProjectPage
authors:
- Benjamin Nye
categories: &id001
- Fall 2023
date: '2023-01-01 00:00:00'
external_link: null
image: null
slides: null
summary: 'Prototype an approach to fine-tune a large language model (LLM) to help
  diagnose areas to improve a specific writing product. For example, scientific papers
  require consistent language but in creative writing variety matters. Proposed steps
  are:

  1. Writing Product: Coordinate with project mentors to choose a common and important
  writing product, such as a position paper or an academic conference. Identify/gather
  a rubric and a corpus.

  3. Inject Bad Writing: For each element of the rubric, develop prompts for generative
  AI to decrease the quality of writing based on the rubric (i.e., make it worse).
  This will form a training data set of the good example and version worse on certain
  characteristics.

  4. Fine Tune: Students will be expected to attempt to fine tune an LLM (e.g., LLAMA
  2) based on this synthetically generated data

  5. Evaluate: Research if tuning suggests better domain-specific areas to improve.


  This project aligns with ongoing work with the USC Generative AI Center.'
tags: *id001
title: 'Bad Writing is "Fine": Tuning an LLM to Suggest Improvements'
url_code: null
url_pdf: null
url_slides: null
url_video: null
weight: 10
---
## Description

Prototype an approach to fine-tune a large language model (LLM) to help diagnose areas to improve a specific writing product. For example, scientific papers require consistent language but in creative writing variety matters. Proposed steps are:
1. Writing Product: Coordinate with project mentors to choose a common and important writing product, such as a position paper or an academic conference. Identify/gather a rubric and a corpus.
3. Inject Bad Writing: For each element of the rubric, develop prompts for generative AI to decrease the quality of writing based on the rubric (i.e., make it worse). This will form a training data set of the good example and version worse on certain characteristics.
4. Fine Tune: Students will be expected to attempt to fine tune an LLM (e.g., LLAMA 2) based on this synthetically generated data
5. Evaluate: Research if tuning suggests better domain-specific areas to improve.

This project aligns with ongoing work with the USC Generative AI Center.




## Advisors

* [Benjamin Nye](../../../author/benjamin-nye)

## Skills Required by the team


* Python
## What students will learn

Generative AI for large language models. Generating synthetic data for a rubric. Fine tuning a large language model, likely using CARC (the on campus computing cluster). Understanding intelligent tutoring system design fundamentals for modeling how experts diagnose issues from novices.