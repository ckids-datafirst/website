---
!ProjectPage
authors:
- Negar Mokhberian
categories: &id001
- Fall 2023
date: '2023-01-01 00:00:00'
external_link: null
image: null
slides: null
summary: 'When it comes to classification tasks, many previous work has tried to design
  larger and more complex neural networks. Recently, the line of data-centric AI has
  worked on shifting the focus to the quality of the train data. This shift arises
  from the recognition that the annotations associated with dataset instances can
  exhibit both noise, stemming from vague instructions or human errors, and bias,
  arising from differing perspectives among annotators in response to given prompts.

  In this project, our objective is to bridge the gap between the two lines of research:
  one dedicated to identifying noisy instances and the other striving to account for
  the diverse perspectives of annotators. Specifically, we will delve into the domain
  of offensive text detection datasets, a highly subjective task. Our investigation
  will center on whether perspectivist classification models have effectively harnessed
  valuable information from instances flagged as noisy by noise-detection techniques. '
tags: *id001
title: Understanding the Relation Between Noise and Bias in Annotated Datasets
url_code: null
url_pdf: null
url_slides: null
url_video: null
weight: 10
---
## Description

When it comes to classification tasks, many previous work has tried to design larger and more complex neural networks. Recently, the line of data-centric AI has worked on shifting the focus to the quality of the train data. This shift arises from the recognition that the annotations associated with dataset instances can exhibit both noise, stemming from vague instructions or human errors, and bias, arising from differing perspectives among annotators in response to given prompts.
In this project, our objective is to bridge the gap between the two lines of research: one dedicated to identifying noisy instances and the other striving to account for the diverse perspectives of annotators. Specifically, we will delve into the domain of offensive text detection datasets, a highly subjective task. Our investigation will center on whether perspectivist classification models have effectively harnessed valuable information from instances flagged as noisy by noise-detection techniques. 




## Advisors

* [Negar Mokhberian](../../../author/negar-mokhberian)

## Skills Required by the team


* Python
* PyTorch
* Fine-tuning language models in Huggingface package