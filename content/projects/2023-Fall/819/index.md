---
!ProjectPage
authors:
- Thomas D. Lyon
categories: &id001
- Fall 2023
date: '2023-01-01 00:00:00'
external_link: null
image: null
slides: null
summary: 'Question type coding is used in research on forensic interviewing to distinguish
  between best practice open-ended questions, and closed-ended and leading questions
  that interviewers are trained to avoid. Most research teams in the field rely on
  a time-consuming and labor-intensive method of question type coding whereby a researcher
  codes every question in the interview, and a second researcher codes a subset to
  demonstrate inter-rater reliability. We are currently working with a graduate of
  the Masters in Computer Science program at USC on a project exploring automated
  question type coding of forensic interviews with victims of child abuse. In collaboration
  with the student, we have trained a large language model (RoBERTa) to distinguish
  between question types based on a rudimentary classification system. In the next
  stage of the project, we are aiming to finetune the model and use zero shot and
  few shot prompting to make distinctions for which there is limited manually-coded
  data.

  '
tags: *id001
title: Automated question type coding of forensic interviews
url_code: null
url_pdf: null
url_slides: null
url_video: null
weight: 10
---
## Description

Question type coding is used in research on forensic interviewing to distinguish between best practice open-ended questions, and closed-ended and leading questions that interviewers are trained to avoid. Most research teams in the field rely on a time-consuming and labor-intensive method of question type coding whereby a researcher codes every question in the interview, and a second researcher codes a subset to demonstrate inter-rater reliability. We are currently working with a graduate of the Masters in Computer Science program at USC on a project exploring automated question type coding of forensic interviews with victims of child abuse. In collaboration with the student, we have trained a large language model (RoBERTa) to distinguish between question types based on a rudimentary classification system. In the next stage of the project, we are aiming to finetune the model and use zero shot and few shot prompting to make distinctions for which there is limited manually-coded data.





## Advisors

* [Thomas D. Lyon](../../../author/thomas-dlyon)

## Skills Required


* Python and/or R