<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Marcin Abram | DataFirst</title><link>https://ckids-datafirst.github.io/website/author/marcin-abram/</link><atom:link href="https://ckids-datafirst.github.io/website/author/marcin-abram/index.xml" rel="self" type="application/rss+xml"/><description>Marcin Abram</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 01 Jan 2023 00:00:00 +0000</lastBuildDate><image><url>https://ckids-datafirst.github.io/website/author/marcin-abram/avatar_hu870bbd5933f20e6603ba5047adbf5cbe_145664_270x270_fill_q75_lanczos_center.jpeg</url><title>Marcin Abram</title><link>https://ckids-datafirst.github.io/website/author/marcin-abram/</link></image><item><title>Learning and forgetting in neural networks</title><link>https://ckids-datafirst.github.io/website/projects/2023-fall/811/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://ckids-datafirst.github.io/website/projects/2023-fall/811/</guid><description>&lt;h2 id="description">Description&lt;/h2>
&lt;p>In this project, you will examine the mechanism responsible for forgetting previous tasks in artificial neural networks. You will study how those mechanisms shape the behavior of neural network learning from heterogeneous data distributions. You will investigate how new information is stored in neural networks by plotting and interpreting the neuron activation patterns. You will also compare different learning schemas, and you will examine how they influence the final loss function landscape.&lt;/p>
&lt;h2 id="advisors">Advisors&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="../../../author/marcin-abram">Marcin Abram&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="skills-required-by-the-team">Skills Required by the team&lt;/h2>
&lt;ul>
&lt;li>Python&lt;/li>
&lt;li>TensorFlow or PyTorch&lt;/li>
&lt;/ul>
&lt;h2 id="what-students-will-learn">What students will learn&lt;/h2>
&lt;p>How the information is stored in neural networks. How neural networks can forget how to perform previously mastered tasks. How to interpret neural networks (by examining the neuron activation patterns). How to conduct scientific experiments (in the domain of machine learning). How to present and visualize scientific data.&lt;/p></description></item><item><title>Scientific Concept Discovery: Using Machine Learning to Advance Scientific Research</title><link>https://ckids-datafirst.github.io/website/projects/2022-spring/604/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://ckids-datafirst.github.io/website/projects/2022-spring/604/</guid><description>&lt;h2 id="description">Description&lt;/h2>
&lt;p>Our group focuses on the question of how to design a learning framework that promote the generalizability of machine learning models. In this project, you will focus on exploring how neural networks acquire information from the training examples and how they learn to solve various physical problems (e.g., emulation of simple quantum systems). The premise of this project is that by observing how a machine learning model learns to solve the specific task, we can learn about the underlying problem itself. As an example, by analyzing the weights of a trained neural network, you can discover non-trivial symmetries of the modeled physical system, determine the relative importance of features, or identify some non-trivial interplay between underlying physical mechanisms. Your task would be to learn various tools for interpreting deep neural networks. You will test them in practice and you will explore methods that promote model transparency and interpretability.&lt;/p>
&lt;h2 id="awards">Awards&lt;/h2>
&lt;ul>
&lt;li>Best Project Achievement&lt;/li>
&lt;/ul>
&lt;h2 id="advisors">Advisors&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="../../../author/marcin-abram">Marcin Abram&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="skills-required-by-the-team">Skills Required by the team&lt;/h2>
&lt;ul>
&lt;li>Python&lt;/li>
&lt;li>PyTorch&lt;/li>
&lt;li>Tensorflow&lt;/li>
&lt;li>Bash&lt;/li>
&lt;li>Quantum Mechanics&lt;/li>
&lt;/ul></description></item></channel></rss>