<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Sara Melotte | DataFirst</title><link>https://ckids-datafirst.github.io/website/author/sara-melotte/</link><atom:link href="https://ckids-datafirst.github.io/website/author/sara-melotte/index.xml" rel="self" type="application/rss+xml"/><description>Sara Melotte</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 01 Jan 2021 00:00:00 +0000</lastBuildDate><image><url>https://ckids-datafirst.github.io/website/media/icon_hu5486d42984c30aaff6be99d37062b147_3155_512x512_fill_lanczos_center_3.png</url><title>Sara Melotte</title><link>https://ckids-datafirst.github.io/website/author/sara-melotte/</link></image><item><title>Discovering and Measuring Biases in Commonsense Knowledge Bases</title><link>https://ckids-datafirst.github.io/website/projects/2021-fall/103/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://ckids-datafirst.github.io/website/projects/2021-fall/103/</guid><description>&lt;h2 id="description">Description&lt;/h2>
&lt;p>Common sense knowledge bases are used widely in research, spanning many areas in artificial intelligence, including natural language understanding, computer vision, and planning. However, these resources may contain human biases, which will ultimately be embedded in the resulting AI solution and potentially have negative societal impacts. The extent to which these biases exist is unclear. In this project, you will define several well-motivated biases (location, gender, ethnicity) and measure the extent to which they are represented in ConceptNet.&lt;/p>
&lt;h2 id="awards">Awards&lt;/h2>
&lt;ul>
&lt;li>Best Data Science Insight&lt;/li>
&lt;/ul>
&lt;h2 id="students">Students&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Linglan Zhang&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Yu Zhang&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Sara Melotte&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Aditya Uday Malte&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Namita Santosh Mutha&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="advisors">Advisors&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="../../../author/fred-morstatter">Fred Morstatter&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="../../../author/filip-ilievski">Filip Ilievski&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="skills-required-by-the-team">Skills Required by the team&lt;/h2>
&lt;ul>
&lt;li>Python&lt;/li>
&lt;li>Statistics&lt;/li>
&lt;li>Machine Learning&lt;/li>
&lt;li>Clustering&lt;/li>
&lt;li>Language Models&lt;/li>
&lt;li>Data Analysis&lt;/li>
&lt;/ul></description></item><item><title>Investigations of a Data Science Online Community</title><link>https://ckids-datafirst.github.io/website/projects/2020-fall/202/</link><pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate><guid>https://ckids-datafirst.github.io/website/projects/2020-fall/202/</guid><description>&lt;h2 id="description">Description&lt;/h2>
&lt;p>The Kaggle.com competition ecosystem is a rich and active community with a designed Progression System that uses performance medals to rank and differentiate users into tiers. However, winning performance medals in Kaggle is more complex than it appears. Users are bound by the available competitions, characteristics of the competition’s problem statement, the quality of their software submissions, and the quality of other competitors (including collaborators). With these factors, one user’s earned “Gold” medal from one competition may have required more effort and a higher quality solution than another user’s earned “Gold” medal in a different competition. This project has great potential to learn about open competitions in data science. Some example questions are: What features help predict whether a user will win a medal in a competition? How can users be clustered and differentiated from one another using their competition patterns and medal-winning solutions? How quickly (in days) will a user win their next competition medal? What is the probability that a user will assemble a team for a competition? What are features that predict high-performing teams? What features help generate teammate recommendations?&lt;/p>
&lt;h2 id="awards">Awards&lt;/h2>
&lt;ul>
&lt;li>Best Interdisciplinary Data Science Team&lt;/li>
&lt;/ul>
&lt;h2 id="students">Students&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Sara Melotte&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Devendra Swami&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Jacob Bickman&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Jae Young Kim&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Kevin Tsang&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="advisors">Advisors&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="../../../author/marlon-twyman">Marlon Twyman&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="skills-required-by-the-team">Skills Required by the team&lt;/h2>
&lt;ul>
&lt;li>Python&lt;/li>
&lt;li>R&lt;/li>
&lt;li>Statistics&lt;/li>
&lt;li>Machine Learning&lt;/li>
&lt;li>R&lt;/li>
&lt;li>Matlab&lt;/li>
&lt;/ul></description></item></channel></rss>